{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyObGZT+xlQLwIZrseRp1Rnz"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp3Yns4vJNjL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756870289020,
     "user_tz": -330,
     "elapsed": 132,
     "user": {
      "displayName": "Rishav Singh",
      "userId": "01870232200983552736"
     }
    },
    "outputId": "5a7c4aa2-9521-435f-b703-d27657b69bd7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing values in any column: False\n",
      "\n",
      "Encoded column: 'Gender'\n",
      "Encoded column: 'Primary_Device'\n",
      "Encoded column: 'Urban_or_Rural'\n",
      "\n",
      "\u2705 Data Preprocessing Done\n",
      "Train shape: (7769, 6) Test shape: (1943, 6)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries and Load dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../datasets/Indian_Kids_Screen_Time.csv\")\n",
    "\n",
    "# Drop the 'Health_Impacts' column as it's complex and not suitable for this model\n",
    "if 'Health_Impacts' in df.columns:\n",
    "    df.drop(\"Health_Impacts\", axis=1, inplace=True)\n",
    "\n",
    "# Check for missing values (Your dataset is clean, so no filling is needed)\n",
    "print(f\"Missing values in any column: {df.isnull().any().any()}\\n\")\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['Gender', 'Primary_Device', 'Urban_or_Rural']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        label_enc = LabelEncoder()\n",
    "        # Make a copy to avoid SettingWithCopyWarning\n",
    "        df.loc[:, col] = label_enc.fit_transform(df[col])\n",
    "        print(f\"Encoded column: '{col}'\")\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found. Skipping encoding.\")\n",
    "\n",
    "\n",
    "# Define the target variable\n",
    "target_col = 'Exceeded_Recommended_Limit'\n",
    "\n",
    "if target_col in df.columns:\n",
    "    # Split features and target\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Create a new DataFrame with scaled features for clarity\n",
    "    X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "\n",
    "    # Train-test split\n",
    "    # Use stratification to maintain the same proportion of target classes in train and test sets\n",
    "    if len(X) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        print(\"\\n\u2705 Data Preprocessing Done\")\n",
    "        print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "    else:\n",
    "        print(\"Error: Not enough data to perform train-test split.\")\n",
    "else:\n",
    "    print(f\"Error: Target column '{target_col}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Data Preprocessing (Refined)\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = ['Gender', 'Primary_Device', 'Urban_or_Rural']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Use .loc to ensure the operation modifies the DataFrame directly\n",
    "        df.loc[:, col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le  # Save encoders if needed later\n",
    "        print(f\"Encoded column: '{col}'\")\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found. Skipping encoding.\")\n",
    "\n",
    "# Define the target variable\n",
    "target_col = 'Exceeded_Recommended_Limit'\n",
    "\n",
    "if target_col in df.columns:\n",
    "    # Split features and target\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Train-Test Split (before scaling)\n",
    "    if len(X) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        # Scale the features (fit on train, transform on both train and test)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        print(\"\\n\u2705 Data preprocessing completed!\")\n",
    "        print(\"Training set shape:\", X_train.shape)\n",
    "        print(\"Test set shape:\", X_test.shape)\n",
    "    else:\n",
    "        print(\"Error: Not enough data to perform train-test split.\")\n",
    "else:\n",
    "    print(f\"Error: Target column '{target_col}' not found in the dataset.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_8f1wAnKFJb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756870339400,
     "user_tz": -330,
     "elapsed": 136,
     "user": {
      "displayName": "Rishav Singh",
      "userId": "01870232200983552736"
     }
    },
    "outputId": "52a6ec5f-8e0d-4198-98d8-5fe2bdd254e4"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoded column: 'Gender'\n",
      "Encoded column: 'Primary_Device'\n",
      "Encoded column: 'Urban_or_Rural'\n",
      "\n",
      "\u2705 Data preprocessing completed!\n",
      "Training set shape: (7769, 6)\n",
      "Test set shape: (1943, 6)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Step 3: Implement Random Forest Classifier ---\n",
    "\n",
    "print(\"--- Training Random Forest Classifier ---\")\n",
    "\n",
    "# Check if training and test data are available (good practice)\n",
    "if 'X_train' in locals() and 'X_test' in locals():\n",
    "    # Initialize Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"\\nRandom Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf, target_names=['Not Exceeded', 'Exceeded']))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "else:\n",
    "    print(\"Training and test data not available. Please run the preprocessing steps first.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jYwXlqwKQDx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756870388668,
     "user_tz": -330,
     "elapsed": 604,
     "user": {
      "displayName": "Rishav Singh",
      "userId": "01870232200983552736"
     }
    },
    "outputId": "2b732cff-822d-43d1-917c-e216a58e6254"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Training Random Forest Classifier ---\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Exceeded       1.00      1.00      1.00       282\n",
      "    Exceeded       1.00      1.00      1.00      1661\n",
      "\n",
      "    accuracy                           1.00      1943\n",
      "   macro avg       1.00      1.00      1.00      1943\n",
      "weighted avg       1.00      1.00      1.00      1943\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 282    0]\n",
      " [   0 1661]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Train-Test Split (before scaling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"--- Data Preprocessing Complete ---\\n\")\n",
    "\n",
    "\n",
    "# --- Step 3: Implement various classifiers with Boosting ---\n",
    "\n",
    "print(\"--- Training and Evaluating Classifiers ---\")\n",
    "\n",
    "# Check if training and test data are available\n",
    "if 'X_train' in locals() and 'X_test' in locals():\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Boosted DT\": AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1, random_state=42), n_estimators=50, random_state=42),\n",
    "        \"Boosted RF\": AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=10, max_depth=1, random_state=42), n_estimators=50, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results[name] = acc\n",
    "        print(f\"{name} Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "    # Comparison table\n",
    "    comparison = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
    "    print(\"\\n--- Final Comparison of Classifiers ---\")\n",
    "    print(comparison)\n",
    "else:\n",
    "    print(\"Training and test data not available. Please run the preprocessing steps first.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raF6ulrxKy-s",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756870490434,
     "user_tz": -330,
     "elapsed": 4846,
     "user": {
      "displayName": "Rishav Singh",
      "userId": "01870232200983552736"
     }
    },
    "outputId": "275616c3-e3ab-4688-d88d-427fd02d5edd"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Data Preprocessing Complete ---\n",
      "\n",
      "--- Training and Evaluating Classifiers ---\n",
      "Training KNN...\n",
      "KNN Accuracy: 0.9650\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.9156\n",
      "\n",
      "Training Boosted DT...\n",
      "Boosted DT Accuracy: 1.0000\n",
      "\n",
      "Training Boosted RF...\n",
      "Boosted RF Accuracy: 1.0000\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 1.0000\n",
      "\n",
      "\n",
      "--- Final Comparison of Classifiers ---\n",
      "                   Accuracy\n",
      "KNN                0.965003\n",
      "Naive Bayes        0.915594\n",
      "Boosted DT         1.000000\n",
      "Boosted RF         1.000000\n",
      "Gradient Boosting  1.000000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"--- Training Boosting Classifiers ---\")\n",
    "\n",
    "# Check if training and test data are available\n",
    "if 'X_train' in locals() and 'X_test' in locals():\n",
    "    # AdaBoost\n",
    "    ada = AdaBoostClassifier(n_estimators=20, random_state=42)\n",
    "    ada.fit(X_train, y_train)\n",
    "    y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, random_state=42)\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "    print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "    print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "else:\n",
    "    print(\"Training and test data not available. Please run the preprocessing steps first.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzsTX-LkLR-T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756870587345,
     "user_tz": -330,
     "elapsed": 228,
     "user": {
      "displayName": "Rishav Singh",
      "userId": "01870232200983552736"
     }
    },
    "outputId": "032a571a-f0c6-4c0c-aec8-4a4e2690d110"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Training Boosting Classifiers ---\n",
      "AdaBoost Accuracy: 1.0\n",
      "Gradient Boosting Accuracy: 1.0\n"
     ]
    }
   ]
  }
 ]
}